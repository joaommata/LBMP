{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5c9be8",
   "metadata": {},
   "source": [
    "### Testing the transcribing of the audio file using Whisper models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e7fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c582d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_base = whisper.load_model(\"base\")  # options: tiny, base, small, medium, large\n",
    "model_medium = whisper.load_model(\"medium\")  # options: tiny, base, small, medium, large\n",
    "model_turbo = whisper.load_model(\"turbo\")  # options: tiny, base, small, medium, large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa64dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaomata/Desktop/LBMP/.venv/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "result_base= model_base.transcribe(\"/Users/joaomata/Desktop/LBMP/E-DAIC/600_P/600_AUDIO.wav\")\n",
    "with open(\"result_base.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result_base, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a068ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [01:03<00:00, 24.0MiB/s]\n",
      "/Users/joaomata/Desktop/LBMP/.venv/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Python(97011) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "result_medium = model_large.transcribe(\"/Users/joaomata/Desktop/LBMP/E-DAIC/600_P/600_AUDIO.wav\")\n",
    "with open(\"result_medium.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result_medium, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce3b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaomata/Desktop/LBMP/.venv/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Python(97610) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "result_turbo = model_turbo.transcribe(\"/Users/joaomata/Desktop/LBMP/E-DAIC/600_P/600_AUDIO.wav\")\n",
    "with open(\"result_turbo.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result_turbo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3855021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the transcription\n",
    "print(\"Result (Base)\")  \n",
    "print(result_base[\"text\"])\n",
    "print(\"Result (Large)\")\n",
    "print(result_medium[\"text\"])\n",
    "print(\"Result (turbo)\")\n",
    "print(result_turbo[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20225230",
   "metadata": {},
   "source": [
    "### Using DepRoBERTa to classify transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87c8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d58bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaomata/Desktop/LBMP/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa681fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Okay. So you're in the bridge, you're in the hoppy, up here for just a second, and I'll go ahead and shrink her back down. Okay. So there she is. So I'm going to go ahead and shrink her back down while I continue setting some things up. Okay. Come on. Okay. Okay. Are you okay with this? Yes. Okay. So, are you going to do it today? I'm fine. Let's go. Where are you from originally? Let's go. Really? Yes. Where are you from originally? Where are you from originally? The weather. Where are you from originally? The crime. I see what you mean. Do you consider yourself a man? I don't know, Demise. Sometimes when I'm feeling tense, I turn on the fist and scream saber. Hey, I know it's not polite, but it's the best I've got. What do you do to relax? Rhyp poetry. What are some things that make you really not? What happens to your mind? Nothing. What do you do when you're in a lot of it? Listen to music. How are you going to control your tongue? Very good. When was the last time you heard this? About a week ago, my husband over cigarettes. Because he wants to stop it now, though. What did you say at school? I dropped out when I was in the Length grade. I could say it. What do you do now? I'm unemployed. Nice. What's your dream job? I would like to become a famous poetry writer. Do you have a job? No. Why? It's too expensive. What's your most memorable experiences? I always let my friends and friends have fun. That's good. I close our into your family. I'm very close. There's something that's been a positive influence in your life. My husband. Can you tell me about that? I used to be a drug addict and he helped me overcome my addiction. I feel better. It's fine. Do you have a mate? No, just my husband. Have you ever served in military? No. Have you ever been diagnosed with PTSD? Yes. How long have you been diagnosed with depression? 2002. Did you think you had an album before you found out? Not really. I overdosed on some pills. 2002. Do you still go with therapy now? No. Excuse me? I'm not a tenant therapy right now. Can you tell me about that? I'm not a tenant therapy right now. I don't go. I'm not comfortable talking about this. I don't feel comfortable talking about this. How do you see me there? I'm not comfortable talking about this. Okay. Sad all the time. I want to do anything. Sleep too much. I don't know. How do you help with that? I run poetry. It helps me a lot. Well, when I get inspired, I just start writing what's on my mind. I'm not comfortable talking about this. I'm not comfortable talking about this. I'm not comfortable talking about this. I'm not comfortable talking about this. Do you feel that way often? Yes. Time to go down? No. How easy is it to get a good sleep? I just go lay down and just do some music for a little while and you know fall asleep? What are you going to do when you just sleep? Cranky. One of the last time I was really happy. Today. I don't know. How are your best friends writing? A happy person. How going? Nothing for high school. I think I lost everything I need to. Thanks for sharing your thoughts with me. Goodbye. I'm just happy today. I feel like...\n",
      "Logits: tensor([[ 0.0612,  0.4660, -0.0235]])\n",
      "Probabilities: tensor([[0.2926, 0.4386, 0.2688]])\n",
      "Predicted class: 1\n",
      "Prediction: Moderate Depression\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Example text to classify\n",
    "# Load text from pickle file\n",
    "with open(\"result_base.pkl\", \"rb\") as f:\n",
    "    result_base = pickle.load(f)\n",
    "\n",
    "text = result_base[\"text\"]\n",
    "print(text)\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Run the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "\n",
    "# Print results\n",
    "print(f\"Logits: {logits}\")\n",
    "print(f\"Probabilities: {probs}\")\n",
    "print(f\"Predicted class: {torch.argmax(probs)}\")\n",
    "\n",
    "labels = [\"No Depression\", \"Moderate Depression\", \"Depression\"]\n",
    "print(f\"Prediction: {labels[torch.argmax(probs)]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
