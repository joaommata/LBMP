{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XtjCb2Q4syg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8PB27pL4uxQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import torch.nn.functional as F\n",
        "from math import sqrt\n",
        "import warnings\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBRb4vVN4wCn"
      },
      "outputs": [],
      "source": [
        "train_ids_path = \"/content/drive/MyDrive/train_ids.tsv\"\n",
        "eval_ids_path  = \"/content/drive/MyDrive/eval_ids.tsv\"\n",
        "\n",
        "def leggi_ids(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [line.split(\"\\t\")[0].strip() for line in f if line.strip()]\n",
        "\n",
        "train_ids = leggi_ids(train_ids_path)\n",
        "eval_ids  = leggi_ids(eval_ids_path)\n",
        "\n",
        "participant_ids = sorted(\n",
        "    [id_ for id_ in {*train_ids, *eval_ids} if id_.isdigit()],\n",
        "    key=int\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDnhTGJU4yoW"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://dcapswoz.ict.usc.edu/wwwedaic/data\"\n",
        "os.makedirs(\"estratti\", exist_ok=True)\n",
        "\n",
        "def get_target_files(pid):\n",
        "    return [\n",
        "        f\"{pid}_P/features/{pid}_OpenFace2.1.0_Pose_gaze_AUs.csv\",\n",
        "        f\"{pid}_P/features/{pid}_vgg16.csv\",\n",
        "        f\"{pid}_P/features/{pid}_CNN_VGG.mat\",\n",
        "    ]\n",
        "\n",
        "def extract_specific_files(tar, pid):\n",
        "    target_files = get_target_files(pid)\n",
        "    estratti = []\n",
        "\n",
        "    for t in target_files:\n",
        "        for member in tar.getmembers():\n",
        "            tar.extract(member, path=\"estratti\")\n",
        "            estratti.append(t)\n",
        "            break\n",
        "    return estratti\n",
        "\n",
        "def verify_mccl_requirements(pid, estratti):\n",
        "    openface_ok = any(\"OpenFace2.1.0_Pose_gaze_AUs.csv\" in f for f in estratti)\n",
        "    f3d_ok = any(\"vgg16.csv\" in f or \"CNN_VGG.mat\" in f for f in estratti)\n",
        "\n",
        "ok_participants = []\n",
        "for pid in participant_ids:\n",
        "    nome_file = f\"{pid}_P.tar.gz\"\n",
        "    link = f\"{base_url}/{nome_file}\"\n",
        "\n",
        "    #print(f\"\\nAt... {nome_file}...\")\n",
        "    response = requests.get(link, stream=True)\n",
        "    with open(nome_file, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    with tarfile.open(nome_file, \"r:gz\") as tar:\n",
        "        estratti = extract_specific_files(tar, pid)\n",
        "    if verify_mccl_requirements(pid, estratti):\n",
        "        ok_participants.append(pid)\n",
        "\n",
        "    # Cancella il file .tar.gz per non occupare spazio => Claude.AI suggestion\n",
        "    os.remove(nome_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xTeGkbL4y-n"
      },
      "outputs": [],
      "source": [
        "class InterviewDataset(Dataset):\n",
        "    def __init__(self, base_path, label_file, split_file, split_type='train', seq_len=1080, num_segments=3, predefined_ids=None):\n",
        "        self.base_path = base_path\n",
        "        self.labels = pd.read_csv(label_file)\n",
        "        self.split_info = pd.read_csv(split_file)\n",
        "        self.split_type = split_type\n",
        "        self.seq_len = seq_len\n",
        "        self.num_segments = num_segments\n",
        "        self.segment_len = seq_len // num_segments\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "        self.pids = []\n",
        "\n",
        "        ### Chat gpt help in this to substitute rndm seed as done before\n",
        "        if predefined_ids is not None:\n",
        "            print(f\"Usando {len(predefined_ids)} IDs predefiniti para {split_type}\")\n",
        "            valid_pids = [str(pid) for pid in predefined_ids]\n",
        "            self.labels = self.labels[self.labels['Participant_ID'].astype(str).isin(valid_pids)]\n",
        "        else:\n",
        "            # usa split file normale\n",
        "            split_pids = self.split_info[self.split_info['split'] == split_type]['Participant'].astype(str).tolist()\n",
        "            self.labels = self.labels[self.labels['Participant_ID'].astype(str).isin(split_pids)]\n",
        "        ### Chat gpt help in this to substitute rndm seed as done before\n",
        "\n",
        "        self.labels = self.labels.rename(columns={'Participant_ID': 'pid'})\n",
        "        available_ids = self._get_available_participant_ids()\n",
        "        available_labels = self.labels[self.labels['pid'].astype(str).isin(available_ids)]\n",
        "\n",
        "        print(f\"{split_type} dataset: {len(available_labels)} participants available\")\n",
        "\n",
        "        for _, row in available_labels.iterrows():\n",
        "            pid = str(row[\"pid\"])\n",
        "            try:\n",
        "                # load openface features\n",
        "                openface_file = os.path.join(base_path, f\"{pid}_P/features/{pid}_OpenFace2.1.0_Pose_gaze_AUs.csv\")\n",
        "                df_of = pd.read_csv(openface_file)\n",
        "                features_dict = {}\n",
        "\n",
        "                f3d_cols = []\n",
        "                for i in range(68):\n",
        "                    f3d_cols.extend([f'x_{i}', f'y_{i}', f'z_{i}'])\n",
        "                available_f3d = [col for col in f3d_cols if col in df_of.columns]\n",
        "                if available_f3d:\n",
        "                    features_dict['f3d'] = df_of[available_f3d].values\n",
        "\n",
        "                gaze_cols = ['gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z']\n",
        "                available_gaze = [col for col in gaze_cols if col in df_of.columns]\n",
        "                if available_gaze:\n",
        "                    features_dict['gaze'] = df_of[available_gaze].values\n",
        "\n",
        "                hp_cols = ['pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz']\n",
        "                available_hp = [col for col in hp_cols if col in df_of.columns]\n",
        "                if available_hp:\n",
        "                    features_dict['hp'] = df_of[available_hp].values\n",
        "\n",
        "\n",
        "                fau_cols = [f'AU{i}_r' for i in [1,2,4,5,6,7,10,12,14,15,17,20,23,25,26,28,45]]\n",
        "                available_faus = [col for col in fau_cols if col in df_of.columns]\n",
        "                if available_faus:\n",
        "                    features_dict['fau'] = df_of[available_faus].values\n",
        "                min_len = min(features.shape[0] for features in features_dict.values())\n",
        "\n",
        "                for key, features in features_dict.items():\n",
        "                    features_dict[key] = features[:min_len]\n",
        "\n",
        "                for key, features in features_dict.items():\n",
        "                    features_clean = pd.DataFrame(features).dropna()\n",
        "                    if len(features_clean) > 0:\n",
        "                        # z-score normalization (google suggestion -> normalize each modality separately)\n",
        "                        normalized = (features_clean - features_clean.mean()) / (features_clean.std() + 1e-8)\n",
        "                        features_dict[key] = normalized.values\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                processed_features = {}\n",
        "                for key, features in features_dict.items():\n",
        "                    if len(features) >= seq_len:\n",
        "                        seq = features[:seq_len]\n",
        "                    else: # padding se troppo corta\n",
        "\n",
        "                        padding = np.zeros((seq_len - len(features), features.shape[1]))\n",
        "                        seq = np.vstack((features, padding))\n",
        "\n",
        "                    segments = []\n",
        "                    for i in range(num_segments):\n",
        "                        start_idx = i * self.segment_len\n",
        "                        end_idx = (i + 1) * self.segment_len\n",
        "                        segment = seq[start_idx:end_idx]\n",
        "                        segments.append(segment)\n",
        "\n",
        "                    processed_features[key] = np.array(segments)\n",
        "\n",
        "                self.data.append(processed_features)\n",
        "                self.targets.append(float(row[\"PHQ_8Total\"]))\n",
        "                self.pids.append(pid)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error with participant {pid}: {e}\")\n",
        "\n",
        "    def _get_available_participant_ids(self):\n",
        "        available_ids = []\n",
        "        if os.path.exists(self.base_path):\n",
        "            for item in os.listdir(self.base_path):\n",
        "                if os.path.isdir(os.path.join(self.base_path, item)) and item.endswith('_P'):\n",
        "                    pid = item.replace('_P', '')\n",
        "                    available_ids.append(pid)\n",
        "        return available_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.data[idx],  # dict with modalities\n",
        "            torch.tensor(self.targets[idx], dtype=torch.float32),\n",
        "            self.pids[idx]\n",
        "        )\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Linear(in_dim, out_dim),\n",
        "            nn.BatchNorm1d(out_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(out_dim, out_dim),\n",
        "            nn.BatchNorm1d(out_dim)\n",
        "        )\n",
        "        self.shortcut = nn.Linear(in_dim, out_dim) if in_dim != out_dim else nn.Identity()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = self.conv(x)\n",
        "        return self.relu(out + residual)\n",
        "\n",
        "class ModalityEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # feature extractor (like ResNet - consiglio di ChatGPT)\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            ResidualBlock(input_dim, hidden_dim),\n",
        "            ResidualBlock(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.bilstm = nn.LSTM(\n",
        "            hidden_dim, hidden_dim // 2,\n",
        "            batch_first=True, bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, input_dim = x.shape\n",
        "        x_flat = x.reshape(-1, input_dim)\n",
        "        features = self.feature_extractor(x_flat)\n",
        "        features = features.reshape(batch_size, seq_len, self.hidden_dim)\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_out, _ = self.bilstm(features)\n",
        "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "        output = self.norm(lstm_out + attn_out)\n",
        "\n",
        "        return output\n",
        "\n",
        "class CrossCharacteristicAttention(nn.Module):\n",
        "    # attention tra modalità diverse\n",
        "    def __init__(self, hidden_dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.cross_attention = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # gate mechanism per controllare interactions\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, modality_features):\n",
        "        enriched_features = {}\n",
        "        modality_names = list(modality_features.keys())\n",
        "\n",
        "        for i, mod_i in enumerate(modality_names):\n",
        "            features_i = modality_features[mod_i]\n",
        "            enhanced_i = features_i.clone()\n",
        "\n",
        "            for j, mod_j in enumerate(modality_names):\n",
        "                if i != j:\n",
        "                    features_j = modality_features[mod_j]\n",
        "                    cross_attn, _ = self.cross_attention(features_i, features_j, features_j)\n",
        "                    concat_features = torch.cat([features_i, cross_attn], dim=-1)\n",
        "                    gate_weights = self.gate(concat_features)\n",
        "                    enhanced_i = enhanced_i + gate_weights * cross_attn\n",
        "\n",
        "            enriched_features[mod_i] = self.norm(enhanced_i)\n",
        "\n",
        "        return enriched_features\n",
        "\n",
        "class TemporalSegmentAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, segment_features):\n",
        "        attn_output, attn_weights = self.attention(segment_features, segment_features, segment_features)\n",
        "        return self.norm(segment_features + attn_output), attn_weights\n",
        "\n",
        "class MCCLModel(nn.Module):\n",
        "    def __init__(self, modality_dims, hidden_dim=64, num_heads=4, num_segments=3):\n",
        "        super().__init__()\n",
        "        self.modality_dims = modality_dims\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_segments = num_segments\n",
        "\n",
        "        # encoder cada modalidade !=\n",
        "        self.modality_encoders = nn.ModuleDict({\n",
        "            modality: ModalityEncoder(dim, hidden_dim, num_heads)\n",
        "            for modality, dim in modality_dims.items()\n",
        "        })\n",
        "\n",
        "        # cross ch. attention\n",
        "        self.cross_char_attention = CrossCharacteristicAttention(hidden_dim, num_heads)\n",
        "\n",
        "        # temporal attention\n",
        "        self.temporal_segment_attention = TemporalSegmentAttention(hidden_dim, num_heads)\n",
        "\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * len(modality_dims), hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(hidden_dim)\n",
        "        )\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=True):\n",
        "        batch_size = next(iter(x.values())).size(0)\n",
        "        segment_representations = []\n",
        "\n",
        "        for segment_idx in range(self.num_segments):\n",
        "            segment_modality_features = {}\n",
        "\n",
        "            for modality, data in x.items():\n",
        "                segment_data = data[:, segment_idx, :, :]\n",
        "                encoded = self.modality_encoders[modality](segment_data)\n",
        "                segment_modality_features[modality] = encoded\n",
        "\n",
        "            enriched_features = self.cross_char_attention(segment_modality_features)\n",
        "\n",
        "            segment_pooled = []\n",
        "            for modality, features in enriched_features.items():\n",
        "                pooled = features.mean(dim=1)\n",
        "                segment_pooled.append(pooled)\n",
        "            segment_concat = torch.cat(segment_pooled, dim=-1)\n",
        "            segment_fused = self.fusion(segment_concat)\n",
        "            segment_representations.append(segment_fused)\n",
        "\n",
        "        segment_features = torch.stack(segment_representations, dim=1)\n",
        "        attended_segments, attention_weights = self.temporal_segment_attention(segment_features)\n",
        "        global_features = attended_segments.mean(dim=1)\n",
        "        output = self.regressor(global_features).squeeze(-1)\n",
        "\n",
        "        if return_features:\n",
        "            return output, global_features, attention_weights\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "def contrastive_loss_paper_style(features, labels, temperature=0.07, margin=2.0):\n",
        "    # normalize features\n",
        "    features_norm = F.normalize(features, p=2, dim=1)\n",
        "\n",
        "    sim_matrix = torch.mm(features_norm, features_norm.t()) / temperature\n",
        "    labels_expanded = labels.unsqueeze(1)\n",
        "    label_diff = torch.abs(labels_expanded - labels_expanded.t())\n",
        "\n",
        "    # positives: same values or very similar\n",
        "    pos_mask = (label_diff < margin).float()\n",
        "    pos_mask.fill_diagonal_(0)  # no som con sé stesso\n",
        "    neg_mask = (label_diff >= margin * 2).float()\n",
        "\n",
        "    # InfoNCE style loss come proposto da Zh.\n",
        "    pos_sim = sim_matrix * pos_mask\n",
        "    neg_sim = sim_matrix * neg_mask\n",
        "\n",
        "    pos_loss = -torch.log(torch.sigmoid(pos_sim) + 1e-8) * pos_mask\n",
        "    neg_loss = -torch.log(1 - torch.sigmoid(neg_sim) + 1e-8) * neg_mask\n",
        "\n",
        "    pos_loss = pos_loss.sum() / (pos_mask.sum() + 1e-8)\n",
        "    neg_loss = neg_loss.sum() / (neg_mask.sum() + 1e-8)\n",
        "\n",
        "    return pos_loss + neg_loss\n",
        "\n",
        "def contrastive_pretraining(model, train_loader, epochs=10, lr=1e-3):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_idx, (x, y, _) in enumerate(train_loader):\n",
        "              # convert modality dict to tensors cf. Reddit\n",
        "            x_tensors = {}\n",
        "            for modality, data in x.items():\n",
        "                x_tensors[modality] = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass para get features\n",
        "            _, features, _ = model(x_tensors, return_features=True)\n",
        "            loss = contrastive_loss_paper_style(features, y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 5 == 0:\n",
        "                print(f\"Pre-train Epoch {epoch+1}/{epochs} | Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Pre-train Epoch {epoch+1} completed | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def fine_tuning_with_contrastive(model, train_loader, val_loader=None, epochs=20, lr=1e-4, contrastive_weight=0.1):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    best_val_mae = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_mae = 0.0\n",
        "        total_rmse = 0.0\n",
        "\n",
        "        for batch_idx, (x, y, _) in enumerate(train_loader):\n",
        "            x_tensors = {}\n",
        "            for modality, data in x.items():\n",
        "                x_tensors[modality] = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output, features, _ = model(x_tensors, return_features=True)\n",
        "            reg_loss = criterion(output, y)\n",
        "\n",
        "            # contrastive + comb. loss\n",
        "            cont_loss = contrastive_loss_paper_style(features, y)\n",
        "            loss = reg_loss + contrastive_weight * cont_loss\n",
        "\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # gradient clipping\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            mae = mean_absolute_error(y.cpu().numpy(), output.detach().cpu().numpy())\n",
        "            rmse = sqrt(mean_squared_error(y.cpu().numpy(), output.detach().cpu().numpy()))\n",
        "            total_mae += mae\n",
        "            total_rmse += rmse\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        val_mae, val_rmse = 0.0, 0.0\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for x_val, y_val, _ in val_loader:\n",
        "                    x_val_tensors = {}\n",
        "                    for modality, data in x_val.items():\n",
        "                        x_val_tensors[modality] = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).to(device)\n",
        "                    y_val = y_val.to(device)\n",
        "\n",
        "                    output_val = model(x_val_tensors, return_features=False)\n",
        "                    val_mae += mean_absolute_error(y_val.cpu().numpy(), output_val.cpu().numpy())\n",
        "                    val_rmse += sqrt(mean_squared_error(y_val.cpu().numpy(), output_val.cpu().numpy()))\n",
        "\n",
        "            val_mae /= len(val_loader)\n",
        "            val_rmse /= len(val_loader)\n",
        "\n",
        "            if val_mae < best_val_mae:\n",
        "                best_val_mae = val_mae\n",
        "                torch.save(model.state_dict(), 'best_mccl_model.pth')\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_mae = total_mae / len(train_loader)\n",
        "        avg_rmse = total_rmse / len(train_loader)\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    # evaluacao do modelo\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    participant_ids = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, pids in dataloader:\n",
        "            x_tensors = {}\n",
        "            for modality, data in x.items():\n",
        "                x_tensors[modality] = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).to(device)\n",
        "\n",
        "            output = model(x_tensors, return_features=False)\n",
        "\n",
        "            predictions.extend(output.cpu().numpy())\n",
        "            targets.extend(y.cpu().numpy())\n",
        "            participant_ids.extend(pids)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    targets = np.array(targets)\n",
        "    #SSe adicionado como previsto cf. whatsapp\n",
        "    mae = mean_absolute_error(targets, predictions)\n",
        "    rmse = sqrt(mean_squared_error(targets, predictions))\n",
        "    sse = np.sum((targets - predictions)**2)\n",
        "\n",
        "    return mae, rmse, sse, predictions, targets, participant_ids\n",
        "\n",
        "def create_results_table(predictions, targets, participant_ids):\n",
        "    results_df = pd.DataFrame({\n",
        "        'Participant_ID': participant_ids,\n",
        "        'PHQ8_Original': targets,\n",
        "        'PHQ8_Predicted': predictions,\n",
        "        'Absolute_Error': np.abs(targets - predictions)\n",
        "    })\n",
        "    results_df = results_df.sort_values('Participant_ID')\n",
        "\n",
        "    return results_df\n",
        "\n",
        "def extract_features_for_xgboost(model, dataloader):\n",
        "    model.eval()\n",
        "    features_list = []\n",
        "    targets_list = []\n",
        "    pids_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y, pids in dataloader:\n",
        "            x_tensors = {}\n",
        "            for modality, data in x.items():\n",
        "                x_tensors[modality] = torch.stack([torch.tensor(d, dtype=torch.float32) for d in data]).to(device)\n",
        "\n",
        "            _, features, _ = model(x_tensors, return_features=True)\n",
        "\n",
        "            features_list.append(features.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "            pids_list.extend(pids)\n",
        "\n",
        "    features_array = np.vstack(features_list)\n",
        "    targets_array = np.array(targets_list)\n",
        "\n",
        "    return features_array, targets_array, pids_list\n",
        "\n",
        "def train_xgboost_final(train_features, train_targets, val_features, val_targets):\n",
        "          # train XGBoost with extracted features per la fine\n",
        "    xgb_params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': 42,\n",
        "        'n_estimators': 200,\n",
        "        'early_stopping_rounds': 20\n",
        "    }\n",
        "\n",
        "    print(\"Training XGBoost finale...\")\n",
        "    xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "\n",
        "    xgb_model.fit(\n",
        "        train_features, train_targets,\n",
        "        eval_set=[(val_features, val_targets)],\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return xgb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxp2LWSJ42Uf"
      },
      "outputs": [],
      "source": [
        "# main execution\n",
        "def main():\n",
        "    base_path = \"/content/estratti\"\n",
        "    label_file = \"/content/drive/MyDrive/Detailed_PHQ8_Labels.csv\"\n",
        "    split_file = \"/content/drive/MyDrive/detailed_lables.csv\"\n",
        "    seq_len = 1080  # Lunghezza sequenza per E-DAIC come da paper\n",
        "    num_segments = 3  # 3 segmenti temporali come nel paper\n",
        "    train_ids_file = \"/content/drive/MyDrive/train_ids.tsv\"\n",
        "    eval_ids_file = \"/content/drive/MyDrive/eval_ids.tsv\"\n",
        "\n",
        "    train_ids_df = pd.read_csv(train_ids_file, sep='\\t')\n",
        "    eval_ids_df = pd.read_csv(eval_ids_file, sep='\\t')\n",
        "    train_participant_ids = train_ids_df.iloc[:, 0].astype(str).tolist()\n",
        "    eval_participant_ids = eval_ids_df.iloc[:, 0].astype(str).tolist()\n",
        "\n",
        "    try:\n",
        "        train_dataset = InterviewDataset(\n",
        "            base_path, label_file, split_file,\n",
        "            split_type='train', seq_len=seq_len, num_segments=num_segments,\n",
        "            predefined_ids=train_participant_ids\n",
        "        )\n",
        "\n",
        "        val_dataset = InterviewDataset(\n",
        "            base_path, label_file, split_file,\n",
        "            split_type='train', seq_len=seq_len, num_segments=num_segments,\n",
        "            predefined_ids=eval_participant_ids\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nel caricamento dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    sample_data = train_dataset[0][0]\n",
        "    modality_dims = {}\n",
        "    for modality, data in sample_data.items():\n",
        "        modality_dims[modality] = data.shape[-1]\n",
        "\n",
        "    train_split_dataset = train_dataset\n",
        "    val_split_dataset = val_dataset\n",
        "    batch_size = min(4, len(train_split_dataset))\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        modality_data = {}\n",
        "        targets = []\n",
        "        pids = []\n",
        "\n",
        "        for modality in batch[0][0].keys():\n",
        "            modality_data[modality] = [item[0][modality] for item in batch]\n",
        "\n",
        "        targets = [item[1] for item in batch]\n",
        "        pids = [item[2] for item in batch]\n",
        "\n",
        "        return modality_data, torch.stack(targets), pids\n",
        "\n",
        "    train_loader = DataLoader(train_split_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_split_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    model = MCCLModel(\n",
        "        modality_dims=modality_dims,\n",
        "        hidden_dim=128,  # da 264; con 64 non cambia granché\n",
        "        num_heads=4,\n",
        "        num_segments=num_segments\n",
        "    )\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    #Contrastativo\n",
        "    contrastive_pretraining(\n",
        "        model,\n",
        "        train_loader,\n",
        "        epochs=10,  # Pre-training contrastivo\n",
        "        lr=1e-3\n",
        "    )\n",
        "\n",
        "    # Salva modello dopo pre-training\n",
        "    torch.save(model.state_dict(), '/content/mccl_pretrained.pth')\n",
        "\n",
        "    # Fine-tuning con Regression + Contrastive Loss\n",
        "    fine_tuning_with_contrastive(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        #epochs=10,  # Fine-tuning\n",
        "        epochs=20,  # Fine-tuning\n",
        "        lr=1e-4,\n",
        "        contrastive_weight=0.1\n",
        "    )\n",
        "\n",
        "    if os.path.exists('best_mccl_model.pth'):\n",
        "        model.load_state_dict(torch.load('best_mccl_model.pth'))\n",
        "\n",
        "    # Estrai features per XGBoost\n",
        "    train_features, train_targets, train_pids = extract_features_for_xgboost(model, train_loader)\n",
        "    val_features, val_targets, val_pids = extract_features_for_xgboost(model, val_loader)\n",
        "    xgb_model = train_xgboost_final(train_features, train_targets, val_features, val_targets)\n",
        "    xgb_predictions = xgb_model.predict(val_features)\n",
        "    mae_xgb = mean_absolute_error(val_targets, xgb_predictions)\n",
        "    rmse_xgb = sqrt(mean_squared_error(val_targets, xgb_predictions))\n",
        "    sse_xgb = np.sum((val_targets - xgb_predictions)**2)\n",
        "    results_df = create_results_table(xgb_predictions, val_targets, val_pids)\n",
        "\n",
        "      # Risultati salvati qui in content => POI LI DEVI SCARICARE!!!\n",
        "    results_df.to_excel('/content/mccl_results.xlsx', index=False)\n",
        "\n",
        "    # Stampa delle metriche finali\n",
        "    print(\"\\nRisultati finali XGBoost (validazione):\")\n",
        "    print(\"MAE:\", mae_xgb)\n",
        "    print(\"RMSE:\", rmse_xgb)\n",
        "    print(\"SSE:\", sse_xgb)\n",
        "\n",
        "    # Mostra le prime 10 righe dei risultati\n",
        "    print(\"\\nFirst 10 (to see più o meno):\")\n",
        "    print(results_df.head(10))\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/mccl_model_final.pth')\n",
        "\n",
        "    import pickle\n",
        "    with open('/content/xgboost_final_model.pkl', 'wb') as f:\n",
        "        pickle.dump(xgb_model, f)\n",
        "\n",
        "    return mae_xgb, rmse_xgb, sse_xgb, results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#Qui sopra OK; ricordati di riconnetterti al runtime + fai che abbia train e val mandati da joao sul gruppo;\n",
        "#i risultati sono grossomodo fedeli al paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Wepl_J43yl"
      },
      "outputs": [],
      "source": [
        "excel_file = '/content/mccl_results.xlsx'\n",
        "files.download(excel_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
